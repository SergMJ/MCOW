{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f59936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sbc_tools as sbc\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cdab39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sermo\\AppData\\Local\\Temp\\ipykernel_11256\\67105503.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"./trained_embeddings_model.pt\")\n",
      "c:\\Users\\sermo\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./trained_embeddings_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3c24590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sermo\\Desktop\\Proyecto RBC\\MCOW\\impl\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a0fd249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCOWAnalyser:\n",
    "    \"\"\"\n",
    "    Property analyser for the \"Many Countries, One World\" ontology.\n",
    "    \"\"\"\n",
    "    \n",
    "    class LocalSemanticSimilarityCalculator:\n",
    "        \"\"\"\n",
    "        Semantic similarity calculator that uses a local MCOW ontology and queries over it.\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self, graph):\n",
    "            \"\"\"\n",
    "            RDF local graph is laoded\n",
    "            \n",
    "            Args:\n",
    "                graph: rdflib.Graph object with the MCOW ontology on it\n",
    "            \"\"\"\n",
    "            self.graph = graph\n",
    "            self.cache = {}\n",
    "            self.wd = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "            self.onto = Namespace(\"http://www.detalle-pais.es/ontology/\")\n",
    "            self.model = torch.load(\"trained_embeddings_model.pt\")\n",
    "        \n",
    "        def execute_query(self, query):\n",
    "            \"\"\"Local SPARQL querying over the local graph\"\"\"\n",
    "            cache_key = hash(query)\n",
    "            if cache_key in self.cache:\n",
    "                return self.cache[cache_key]\n",
    "            \n",
    "            try:\n",
    "                results = self.graph.query(query)\n",
    "                result_list = list(results)\n",
    "                self.cache[cache_key] = result_list\n",
    "                return result_list\n",
    "            except Exception as e:\n",
    "                print(f\"Error en consulta SPARQL: {e}\")\n",
    "                return []\n",
    "            \n",
    "        def get_least_common_subsumer(self, entity1_qid, entity2_qid):\n",
    "            \"\"\"\n",
    "            Finds the Least Common Subsumer (LCS) between two given entities.\n",
    "            \"\"\"\n",
    "\n",
    "            query = f\"\"\"\n",
    "            PREFIX wd:   <http://www.wikidata.org/entity/>\n",
    "            PREFIX onto: <http://www.detalle-pais.es/ontology/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "            SELECT DISTINCT ?lcs ?lcsLabel WHERE {{\n",
    "                wd:{entity1_qid} rdf:type ?reg1 .\n",
    "                wd:{entity2_qid} rdf:type ?reg2 .\n",
    "                \n",
    "                FILTER(STRSTARTS(STR(?reg1), \"http://www.detalle-pais.es/ontology/\"))\n",
    "                FILTER(STRSTARTS(STR(?reg2), \"http://www.detalle-pais.es/ontology/\"))\n",
    "                \n",
    "                ?reg1 rdfs:subClassOf* ?lcs .\n",
    "                ?reg2 rdfs:subClassOf* ?lcs .\n",
    "                FILTER(STRSTARTS(STR(?lcs), \"http://www.detalle-pais.es/ontology/\"))\n",
    "                \n",
    "                FILTER NOT EXISTS {{\n",
    "                    ?deeper rdfs:subClassOf+ ?lcs .\n",
    "                    ?reg1 rdfs:subClassOf* ?deeper .\n",
    "                    ?reg2 rdfs:subClassOf* ?deeper .\n",
    "                }}\n",
    "                \n",
    "                OPTIONAL {{ ?lcs rdfs:label ?lcsLabel }}\n",
    "            }}\n",
    "            ORDER BY DESC(STRLEN(STR(?lcs)))\n",
    "            LIMIT 1\n",
    "            \"\"\"\n",
    "\n",
    "            results = self.execute_query(query)\n",
    "            if results:\n",
    "                lcs_uri = str(results[0].lcs)\n",
    "                label = str(results[0].lcsLabel) if results[0].lcsLabel else None\n",
    "                return lcs_uri, label or lcs_uri.split(\"/\")[-1]\n",
    "            return None, None\n",
    "        \n",
    "        def get_depth(self, entity_qid):\n",
    "            \"\"\"\n",
    "            Calculates the depth of a given entity.\n",
    "            \"\"\"\n",
    "            query = f\"\"\"\n",
    "            PREFIX wd:   <http://www.wikidata.org/entity/>\n",
    "            PREFIX onto: <http://www.detalle-pais.es/ontology/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "            SELECT (COUNT(DISTINCT ?ancestor) AS ?count) WHERE {{\n",
    "                wd:{entity_qid} rdf:type ?reg .\n",
    "                \n",
    "                FILTER(STRSTARTS(STR(?reg), \"http://www.detalle-pais.es/ontology/\"))\n",
    "                \n",
    "                ?reg rdfs:subClassOf* ?ancestor .\n",
    "                \n",
    "                FILTER(STRSTARTS(STR(?ancestor), \"http://www.detalle-pais.es/ontology/\"))\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "            results = self.execute_query(query)\n",
    "            return int(results[0][\"count\"]) if results else 0\n",
    "        \n",
    "        def get_depth_bis(self, entity_qid):\n",
    "            \"\"\"\n",
    "            Calculates the depth of a given entity.\n",
    "            \"\"\"\n",
    "            if entity_qid.startswith(\"http\"):\n",
    "                lcs_uri = f\"<{entity_qid}>\"\n",
    "            else:\n",
    "                lcs_uri = f\"onto:{entity_qid}\"\n",
    "\n",
    "            query = f\"\"\"\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX onto: <http://www.detalle-pais.es/ontology/>\n",
    "\n",
    "            SELECT (COUNT(DISTINCT ?ancestor) AS ?count) WHERE {{\n",
    "                {lcs_uri} rdfs:subClassOf* ?ancestor .\n",
    "                FILTER(STRSTARTS(STR(?ancestor), \"http://www.detalle-pais.es/ontology/\"))\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "            results = self.execute_query(query)\n",
    "            if results and len(results) > 0:\n",
    "                return int(results[0][\"count\"])\n",
    "            return 0\n",
    "        \n",
    "        def wu_palmer_similarity(self, entity1_qid, entity2_qid):\n",
    "            \"\"\"\n",
    "            Wu & Palmer similarity = 2 * depth(lcs) / (depth(c1) + depth(c2))\n",
    "            \"\"\"\n",
    "            lcs_qid, _ = self.get_least_common_subsumer(entity1_qid, entity2_qid)\n",
    "            if not lcs_qid:\n",
    "                return (None, 0.0)\n",
    "            \n",
    "            depth1 = self.get_depth(entity1_qid)\n",
    "            depth2 = self.get_depth(entity2_qid)\n",
    "            depth_lcs = self.get_depth_bis(lcs_qid)\n",
    "            \n",
    "            if depth1 + depth2 == 0:\n",
    "                return (None, 0.0)\n",
    "            \n",
    "            similarity = (2.0 * depth_lcs) / (depth1 + depth2)\n",
    "            lcs_qid = lcs_qid.split(\"/\")[-1]\n",
    "            \n",
    "            return (lcs_qid, similarity)\n",
    "        \n",
    "        def get_property_values(self, country_wd_code, property_name):\n",
    "            \"\"\"\n",
    "            Gets property-value pairs of a given entity\n",
    "            \"\"\"\n",
    "            \n",
    "            query = f\"\"\"\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "\n",
    "            SELECT ?property ?value WHERE {{\n",
    "                wd:{country_wd_code} ?property ?value .\n",
    "                FILTER regex(str(?property), \"{property_name}\", \"i\")\n",
    "            }}\n",
    "            \"\"\"\n",
    "                        \n",
    "            results = graph.query(query)\n",
    "            \n",
    "            return set([str(row.value) for row in results])\n",
    "        \n",
    "        def jaccard_property_similarity(self, country_one_wd_code, country_two_wd_code, property_name):\n",
    "            \"\"\"\n",
    "            Jaccard similarity calc used on categorical attributes classification \n",
    "            (mainly, when analysing neighbours)\n",
    "            Jaccard = |props(e1) ∩ props(e2)| / |props(e1) ∪ props(e2)|\n",
    "            \"\"\"\n",
    "            props1 = self.get_property_values(country_one_wd_code, property_name)\n",
    "            props2 = self.get_property_values(country_two_wd_code, property_name)\n",
    "            \n",
    "            if not props1 and not props2:\n",
    "                return 0.0\n",
    "            \n",
    "            intersection = len(props1 & props2)\n",
    "            union = len(props1 | props2)\n",
    "            \n",
    "            if union == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            return intersection / union\n",
    "            \n",
    "\n",
    "        def attribute_similarity(self, country_one, country_two, property_name):\n",
    "            \"\"\"\n",
    "            Returns the division of the values of a given property\n",
    "            \"\"\"\n",
    "            query = f\"\"\"                \n",
    "                SELECT DISTINCT ?entityOneLabel ?entityTwoLabel ?propertyOneValue ?propertyTwoValue WHERE {{\n",
    "                    wd:{country_one} onto:{property_name} ?propertyOneValue.\n",
    "                    wd:{country_two} onto:{property_name} ?propertyTwoValue.\n",
    "                }}\n",
    "\n",
    "                LIMIT 1     # Avoid wasting unnecessary time looking for more triples that are not needed\n",
    "            \"\"\"\n",
    "            property_one_value = 0\n",
    "            property_two_value = 0\n",
    "\n",
    "            result = graph.query(query)\n",
    "\n",
    "            for row in result:\n",
    "                property_one_value = float(row.propertyOneValue)\n",
    "                property_two_value = float(row.propertyTwoValue)\n",
    "                \n",
    "                print(f\"Property one: {property_one_value}\\nProperty two: {property_two_value}\")\n",
    "\n",
    "            return min(property_one_value, property_two_value) / max(property_one_value, property_two_value)\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador con un grafo de MCOW, precargando además\n",
    "        el diccionario de países disponibles para las futuras consultas.\n",
    "        \n",
    "        Se utiliza un diccionario como caché, para almacenar los resultados\n",
    "        de las consultas y así evitar volver a procesar una consulta ya ejecutada.\n",
    "        \n",
    "        Args:\n",
    "            graph: objeto graph de rdflib con la ontología de MCOW.\n",
    "            \n",
    "        \"\"\"\n",
    "        self.graph = graph\n",
    "        self.cache = {}\n",
    "        self.__init_country_list()\n",
    "        self._init_numerical_attributes_list()\n",
    "        self.local_similarity_calculator = self.LocalSemanticSimilarityCalculator(graph)\n",
    "        \n",
    "        print(f\"{len(self.graph)} triples loaded.\")\n",
    "    \n",
    "    def __init_country_list(self):\n",
    "        countries_query = \"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "                PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "                \n",
    "                SELECT DISTINCT ?entity ?entityLabel ?value WHERE {\n",
    "                    ?entity rdf:type ?class ;\n",
    "                    \n",
    "                    ?property ?value.\n",
    "                \n",
    "                    # Solo entidades de Wikidata\n",
    "                    FILTER(STRSTARTS(STR(?entity), STR(wd:)))\n",
    "                    FILTER regex(str(?property), \"alpha\", \"i\") \n",
    "                    \n",
    "                    \n",
    "                    ?entity rdfs:label ?entityLabel\n",
    "                \n",
    "                }\n",
    "                \n",
    "                ORDER BY ASC(?entityLabel)\n",
    "        \"\"\"\n",
    "\n",
    "        results = self.graph.query(countries_query)\n",
    "        self.countries_in_ontology = dict()\n",
    "\n",
    "        for row in results:\n",
    "            country_uri = str(row.entity).split(\"Q\")[-1]\n",
    "            country_name = str(row.entityLabel)\n",
    "            alpha_code = str(row.value)\n",
    "            \n",
    "            self.countries_in_ontology[country_name] = (country_uri, alpha_code)\n",
    "        \n",
    "        print(f\"MCOW ontology contains {len(self.countries_in_ontology)} countries.\")\n",
    "        \n",
    "    def _init_numerical_attributes_list(self):\n",
    "        \n",
    "        numerical_attributes_query=\"\"\"\n",
    "            SELECT DISTINCT ?property WHERE {\n",
    "                ?entity rdf:type ?class;\n",
    "                ?property ?value.\n",
    "                \n",
    "                # Solo entidades de Wikidata\n",
    "                FILTER(STRSTARTS(STR(?entity), STR(wd:)))\n",
    "                FILTER(STRSTARTS(STR(?property), STR(onto:)))\n",
    "                \n",
    "                FILTER NOT EXISTS{\n",
    "                    FILTER regex(str(?property), \"classification$\", \"i\")  # Exclude classifications.\n",
    "                }\n",
    "                \n",
    "                FILTER NOT EXISTS{\n",
    "                    FILTER regex(str(?property), \"(alpha|continent|is_neighbour_of|subregion|time_zone)\", \"i\")  # Exclude non-numeric values too, as they\n",
    "                                                                                                                # make no sense when analysing tendencies.\n",
    "                }\n",
    "                \n",
    "            }\n",
    "                \n",
    "            ORDER BY ASC(?property)\n",
    "                    \n",
    "            \"\"\"\n",
    "\n",
    "        self.numerical_attributes_list = list()\n",
    "        results = graph.query(numerical_attributes_query)\n",
    "\n",
    "        for row in results:\n",
    "            attribute = row.property.split(\"/\")[-1]\n",
    "            self.numerical_attributes_list.append(attribute)\n",
    "        \n",
    "        print(f\"MCOW ontology contains {len(self.numerical_attributes_list)} numerical attributes.\")\n",
    "    \n",
    "    def get_countries_dict(self):\n",
    "        return self.countries_in_ontology\n",
    "        \n",
    "    def show_cache_keys(self):\n",
    "        return self.cache.keys()\n",
    "    \n",
    "    def anaylse_country_values(self, country_wd_code, ratio_name, mode: Optional[str]=\"I\"):\n",
    "        \"\"\"\n",
    "        Calculates over the graph the countries having the desired property and following\n",
    "        an increasing or decrasing tendency (both counting on an adjustment factor to avoid strict comparisons).\n",
    "        \n",
    "        **Args\"\":\n",
    "        \n",
    "        -> country_wd_code: the Wikidata code of the country (e.g.: Spain -> Q29).\n",
    "        \n",
    "        -> ratio_name: the desired attribute of the entity whose tendency is to analyse.\n",
    "        \n",
    "        -> mode: how the aimed tendency should look like, \"I\" for strictly increasing and \"D\"\n",
    "        for strictly decreasing.\n",
    "        \n",
    "        **Returns\"\":\n",
    "        \n",
    "        -> Two values: \"total\", that shows the amount of subEntities that contains the\n",
    "        desired ratio and \"totalFiltered\", which shows how many of the total fulfills the\n",
    "        series requirement.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if mode.lower() not in [\"d\", \"i\"]:\n",
    "            raise Exception(\"Please, introduce a valid mode (empty or 'I' for increasing values,\"\n",
    "                            \" 'D' for decreasing ones).\")\n",
    "\n",
    "        if not country_wd_code.startswith(\"Q\"):\n",
    "            raise Exception(\"Please, introduce a valid Wikidata entity.\")\n",
    "        \n",
    "        if country_wd_code not in self.countries_in_ontology.values():\n",
    "            raise Exception(f\"The introduced country '{country_wd_code}' code is not a valid country code or does not belong to the current ontology.\")\n",
    "        \n",
    "        operator = \"<\" if mode==\"I\" else \">\"    # Increasing -> first value < second value // Decreasing -> first value > second value\n",
    "        \n",
    "        dynamic_factor_condition = \"(?propertyValueTwo/?propertyValueOne)*100) >= 90)\" if operator == \"<\" else \"(?propertyValueTwo/?propertyValueOne)*100) >= 110)\"     # Adjust factor that allows non-strict\n",
    "                                                                                                                                                                        # increasing/decreasing analysis of attributes,\n",
    "                                                                                                                                                                        # as long as they also fulfill that the last and the\n",
    "                                                                                                                                                                        # first values of the series meet the initial criteria\n",
    "        \n",
    "        cache_id = country_wd_code + \"_\" + ratio_name + \"_\" + mode\n",
    "        cache_id = cache_id.lower()\n",
    "        \n",
    "        if cache_id not in self.cache:      # Cache checking, just in case the result is already there\n",
    "\n",
    "            user_query = f\"\"\"\n",
    "                            SELECT DISTINCT (COUNT (DISTINCT ?temporalSubentityOne) AS ?totalFiltered) ?total ?propertyValueOne ?anyoOne ?propertyValueTwo ?anyoTwo WHERE {{\n",
    "\n",
    "                ?temporalSubentityOne rdfs:subClassOf wd:{country_wd_code};\n",
    "                                    onto:{ratio_name} ?propertyValueOne;\n",
    "                                    onto:anyo ?anyoOne.\n",
    "            \n",
    "                ?temporalSubentityTwo rdfs:subClassOf wd:{country_wd_code};\n",
    "                                    onto:{ratio_name} ?propertyValueTwo;\n",
    "                                    onto:anyo ?anyoTwo.\n",
    "\n",
    "                {{\n",
    "                    SELECT ?anyo (COUNT (DISTINCT ?temporalSubentity) AS ?total) WHERE {{\n",
    "                        ?temporalSubentity rdfs:subClassOf wd:{country_wd_code};\n",
    "                                        onto:{ratio_name} ?propertyValue;\n",
    "                                        onto:anyo ?anyo.\n",
    "                    }}\n",
    "                }}\n",
    "\n",
    "\n",
    "                FILTER(?anyoTwo > ?anyoOne && (?propertyValueOne {operator} ?propertyValueTwo || ({dynamic_factor_condition})\n",
    "            \n",
    "                FILTER NOT EXISTS {{\n",
    "                    ?temporalSubentityPrev rdfs:subClassOf wd:{country_wd_code};\n",
    "                                        onto:{ratio_name} ?propertyValuePrev;\n",
    "                                        onto:anyo ?anyoPrev.\n",
    "                    FILTER(?anyoPrev > ?anyoOne && ?anyoPrev < ?anyoTwo)  # Makes sure no year exists between the pair\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "\n",
    "                \"\"\"\n",
    "            \n",
    "            first_val = \"\"\n",
    "            last_val = \"\"\n",
    "            \n",
    "            first_value_query = f\"\"\"\n",
    "                SELECT DISTINCT ?propertyValue WHERE {{\n",
    "                    ?temporalSubentity rdfs:subClassOf wd:{country_wd_code};\n",
    "                    onto:{ratio_name} ?propertyValue;\n",
    "                    onto:anyo ?anyo.\n",
    "                }}\n",
    "            \n",
    "                ORDER BY ASC(?anyo)\n",
    "                LIMIT 1\"\"\"\n",
    "            \n",
    "            results = self.graph.query(first_value_query)\n",
    "            for row in results:\n",
    "                first_val = row.propertyValue\n",
    "            \n",
    "            last_value_query = f\"\"\"\n",
    "                SELECT DISTINCT ?propertyValue WHERE {{\n",
    "                    ?temporalSubentity rdfs:subClassOf wd:{country_wd_code};\n",
    "                    onto:{ratio_name} ?propertyValue;\n",
    "                    onto:anyo ?anyo.\n",
    "                }}\n",
    "            \n",
    "                ORDER BY DESC(?anyo)\n",
    "                LIMIT 1\"\"\"\n",
    "            \n",
    "            results = self.graph.query(last_value_query)\n",
    "            for row in results:\n",
    "                last_val = row.propertyValue\n",
    "                \n",
    "            print(f\"First val: {first_val} Last val {last_val}\")\n",
    "            \n",
    "            if (operator == \"<\" and first_val<last_val) or (operator == \">\" and first_val>last_val):    # If, even with the factor adjustement corrections the original\n",
    "                                                                                                        # criteria is met, the value is returned.\n",
    "                results = self.graph.query(user_query)\n",
    "                print(country_wd_code)\n",
    "                for row in results:\n",
    "                    print(row.total, row.totalFiltered)\n",
    "                    result_dict = {\"total\":row.total, \"totalFiltered\":row.totalFiltered}\n",
    "                    self.cache[cache_id] = result_dict\n",
    "                    \n",
    "                    return result_dict   # Just a single result, returned inmediately\n",
    "            \n",
    "            return dict()       # Else, an empty dictionary is returned, as the condition has not been met.\n",
    "        \n",
    "        else:   # Already processed query; better avoid executing it again\n",
    "            \n",
    "            return self.cache[cache_id]\n",
    "        \n",
    "    \n",
    "    def analyse_graph_values(self, ratio_name, mode: Optional[str]=\"I\"):\n",
    "        \"\"\"\n",
    "        Calls \"analyse_country_values\" for each country in the graph, returning the WD code\n",
    "        and the country name of those who fulfill the request.\n",
    "        \n",
    "        **Args\"\":\n",
    "        \n",
    "        -> ratio_name: the desired attribute of the entity whose tendency is to analyse.\n",
    "        \n",
    "        -> mode: how the aimed tendency should look like, \"I\" for strictly increasing and \"D\"\n",
    "        for strictly decreasing.\n",
    "        \n",
    "        **Returns\"\":\n",
    "        \n",
    "        -> A dictionary containing the Wikidata key and the name of the countries that\n",
    "        fulfill the requirements.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if mode.lower() not in [\"d\", \"i\"]:\n",
    "            raise Exception(\"Please, introduce a valid mode (empty or 'I' for increasing values,\"\n",
    "                            \" 'D' for decreasing ones).\")\n",
    "        \n",
    "        if ratio_name not in self.numerical_attributes_list:\n",
    "            raise Exception(\"The introduced ratio is mispelled or does not belong to the ontology.\")\n",
    "        \n",
    "        result_dict = dict()\n",
    "\n",
    "        for country_name, country_id in self.countries_in_ontology.items():\n",
    "            result = self.anaylse_country_values(country_id, ratio_name, mode)\n",
    "            \n",
    "            print(result)\n",
    "            \n",
    "            if \"total\" in result and \"totalFiltered\" in result and result[\"totalFiltered\"]:\n",
    "                total = int(result[\"total\"])\n",
    "                totalFiltered = int(result[\"totalFiltered\"])\n",
    "                \n",
    "                if(totalFiltered==total-1):     # If the tendency is absolutely strict, the country is\n",
    "                                                # added to the returning dictionary.\n",
    "                    result_dict[country_name] = country_id\n",
    "\n",
    "        return result_dict\n",
    "    \n",
    "    \n",
    "    def multi_analyse_graph_values(self, ratio_dict):\n",
    "        \"\"\"\n",
    "        Calls \"analyse_country_values\" for each country in the graph, returning the WD code\n",
    "        and the country name of those who fulfill each single request, and then doing set intersection\n",
    "        to return the countries that matches all of them.\n",
    "        \n",
    "        **Args\"\":\n",
    "        \n",
    "        -> ratio_dict: a dictionary of pairs ratio-mode with the metrics that want to be checked out\n",
    "        (e.g.: {\"inflation_rate\":\"D\", \"natality_rate\":\"I\"})\n",
    "        \n",
    "        **Returns\"\":\n",
    "        \n",
    "        -> A dictionary containing the Wikidata key and the name of the countries that\n",
    "        fulfill ALL the requirements (through set intersection).\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        res_dict = dict()\n",
    "        res_set = set()\n",
    "        \n",
    "        for ratio, mode in ratio_dict.items():\n",
    "            \n",
    "            if ratio not in self.numerical_attributes_list:\n",
    "                raise Exception(\"The introduced ratio is mispelled or does not belong to the ontology.\")\n",
    "            \n",
    "            called_dict = self.analyse_graph_values(ratio, mode)\n",
    "            called_set = set([k for k,v in called_dict.items()])\n",
    "            \n",
    "            print(called_dict)\n",
    "            \n",
    "            if len(res_dict) == 0:\n",
    "                res_dict = called_dict.copy()\n",
    "                res_set = called_set\n",
    "            else:\n",
    "                res_set = res_set.intersection(called_set)\n",
    "                res_dict = {k:v for k,v in res_dict.items() if k in res_set}\n",
    "                print(res_dict)\n",
    "        \n",
    "        return res_dict\n",
    "    \n",
    "    \n",
    "    def getDAFOAnalysis(self, country_wd_code):\n",
    "        \"\"\"\n",
    "        Computes an analysis of the given country and returns a dictionary with the strengths and\n",
    "        the weaknesses of it.\n",
    "                \n",
    "        **Args\"\":\n",
    "        \n",
    "        -> country_wd_code: the Wikidata code of the country (e.g.: Spain -> Q29).\n",
    "        \n",
    "        **Returns\"\":\n",
    "        \n",
    "        -> A dictionary whose keys are \"strengths\"/\"weaknesses\" and the values another dictionary\n",
    "        whose keys are the analysed classification and whose value is to which one they belong\n",
    "        (e.g.: {\n",
    "                \"strengths\":{\"mortality_classification\":\"very_low_mortality\"}, \n",
    "                \"weaknesses\": {\"natality_classification\":\"very_low_natality\"}\n",
    "                }\n",
    "        ).\n",
    "        \"\"\"\n",
    "        \n",
    "        dafoQuery = f\"\"\"\n",
    "        \n",
    "        SELECT DISTINCT ?propertyName ?propertyValue WHERE {{\n",
    "          wd:{country_wd_code} ?propertyName ?propertyValue.\n",
    "          FILTER(STRENDS(STR(?propertyName), \"classification\"))\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        if country_wd_code not in self.countries_in_ontology.values():\n",
    "            raise Exception(f\"The introduced country code '{country_wd_code}' is not a valid country code or does not belong to the current ontology.\")\n",
    "        \n",
    "        cache_id = \"dafo_\" + country_wd_code\n",
    "        \n",
    "        if cache_id not in self.cache:\n",
    "        \n",
    "            concepts_set_one = [\"natality\", \"rural_access\", \"urban_access\"]     # Concepts that are better the highest possible\n",
    "            concepts_set_two = [\"unscolarization\", \"unemployment_rate\", \"mortality\", \"inflation_rate\", \"debt\"]   # Concepts that are better the lowest possible\n",
    "            strengths_list = [\"age_balanced_population\"]\n",
    "            weaknesses_list = [\"extremely_elder_population\", \"majorly_elder_population\", \"extremely_underaged_population\"]\n",
    "            \n",
    "            for concept in concepts_set_one:\n",
    "                strengths_list.append(\"high_\" + concept)\n",
    "                strengths_list.append(\"very_high_\" + concept)\n",
    "                weaknesses_list.append(\"low_\" + concept)\n",
    "                weaknesses_list.append(\"very_low_\" + concept)\n",
    "\n",
    "            for concept in concepts_set_two:\n",
    "                strengths_list.append(\"low_\" + concept)\n",
    "                strengths_list.append(\"very_low_\" + concept)\n",
    "                weaknesses_list.append(\"high_\" + concept)\n",
    "                weaknesses_list.append(\"very_high_\" + concept)\n",
    "                \n",
    "            result_strengths = dict()\n",
    "            result_weaknesses = dict()\n",
    "\n",
    "            results = graph.query(dafoQuery)\n",
    "            \n",
    "            for row in results:\n",
    "                propertyName = str(row.propertyName)\n",
    "                propertyValue = str(row.propertyValue)\n",
    "                \n",
    "                if propertyValue in strengths_list:\n",
    "                    result_strengths[propertyName] = propertyValue\n",
    "                    \n",
    "                elif propertyValue in weaknesses_list:\n",
    "                    result_weaknesses[propertyName] = propertyValue\n",
    "            \n",
    "            res_dict = {\"strengths\": result_strengths, \"weaknesses\": result_weaknesses}\n",
    "            \n",
    "            self.cache[cache_id] = res_dict\n",
    "            \n",
    "            return res_dict\n",
    "        \n",
    "        else:\n",
    "            return self.cache[cache_id]\n",
    "    \n",
    "    \n",
    "    def getAttributesSimilarity(self, country_one_wd_code, country_two_wd_code, attribute_set_chosen):\n",
    "        \"\"\"\n",
    "        Computes the similarity between two given countries by certain attributes in function of\n",
    "        the chosen set, being it:\n",
    "\n",
    "            -> Demographic (D): analyses population based aspects (natality rate, life expectancy...)\n",
    "            -> Economical (E): studies economical properties (public debt rate, inflation incurred...)        \n",
    "            -> Social (S): takes on social issues (medical coverage, education...)\n",
    "            -> Territorial (T): computes structural similarity and analyses some territorial attributes (neighbours, area extension)\n",
    "                \n",
    "        **Args\"\":\n",
    "        \n",
    "        -> country_one_wd_code: the Wikidata code of the first country (e.g.: Spain -> Q29).\n",
    "        \n",
    "        -> country_two_wd_code: the Wikidata code of the second country (e.g.: Portugal -> Q45).\n",
    "        \n",
    "        -> attribute_set_chosen: code of the attributes to be analysed\n",
    "        \n",
    "        **Returns\"\":\n",
    "        \n",
    "        -> A float (0, 1) indicating the similarity of the given countries\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if country_one_wd_code not in self.countries_in_ontology.values():\n",
    "            raise Exception(f\"The introduced country code '{country_one_wd_code}' is not a valid country code or does not belong to the current ontology.\")\n",
    "        \n",
    "        if country_two_wd_code not in self.countries_in_ontology.values():\n",
    "            raise Exception(f\"The introduced country code '{country_two_wd_code}' is not a valid country code or does not belong to the current ontology.\")\n",
    "        \n",
    "        if attribute_set_chosen.lower() not in [\"d\", \"e\", \"s\", \"t\"]:\n",
    "            raise Exception(\"Please, introduce a valid mode ('D' for demographic, 'E' for economical,\"\n",
    "                            \" 'S' for social or 'T' for territorial analysis).\")\n",
    "        \n",
    "        social_attributes = [\"rural_sanitation_access\", \"urban_sanitation_access\", \"unemployment_rate\", \"youth_unscolarized_percentage\"]\n",
    "        demographic_attributes = [\"average_children\", \"life_expectancy\", \"mortality_rate\", \"natality_rate\", \"population\", \"population_growth_rate\", \"0_to_14_years\", \"15_to_64_years\", \"65_years_and_over\"]\n",
    "        economic_attributes = [\"economical_growth_rate\", \"inflation_rate\", \"public_debt_rate\"]\n",
    "        territorial_attributes = [\"area_int\", \"is_neighbour_of\"]    # Still need continent, subregion and time_zone, but these will be evaluated through graph hierarchies\n",
    "        \n",
    "        option = attribute_set_chosen.lower()\n",
    "        \n",
    "        if option == \"t\":\n",
    "            \n",
    "            lcs, palmer_similarity = self.local_similarity_calculator.wu_palmer_similarity(country_one_wd_code, country_two_wd_code)\n",
    "            scalar_values_similarity = self.local_similarity_calculator.attribute_similarity(country_one_wd_code, country_two_wd_code, territorial_attributes[0])\n",
    "            categorical_values_similarity = self.local_similarity_calculator.jaccard_property_similarity(country_one_wd_code, country_two_wd_code, territorial_attributes[1])\n",
    "            \n",
    "            computed_value = 0.75*palmer_similarity + 0.125*scalar_values_similarity + 0.125*categorical_values_similarity\n",
    "            \n",
    "            return {\"total\": computed_value, \"palmer_sim\": palmer_similarity, \"lcs\": lcs, \"scalar\": scalar_values_similarity, \"jaccard\": categorical_values_similarity}\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            chosen_numerical_set = list()\n",
    "            \n",
    "            if option == \"d\":\n",
    "                chosen_numerical_set = demographic_attributes\n",
    "            elif option == \"e\":\n",
    "                chosen_numerical_set = economic_attributes\n",
    "            else:\n",
    "                chosen_numerical_set = social_attributes\n",
    "                \n",
    "            computed_value = 0\n",
    "            \n",
    "            for attr in chosen_numerical_set:\n",
    "                computed_value += self.local_similarity_calculator.attribute_similarity(country_one_wd_code, country_two_wd_code, attr)\n",
    "            \n",
    "            computed_value /= len(chosen_numerical_set)\n",
    "                \n",
    "            return {\"total\": computed_value, \"scalar\": computed_value}\n",
    "    \n",
    "    \n",
    "    def obtener_embedding_entidad(model, entity_name: str, entity_to_id: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Obtiene el vector embedding de una entidad\n",
    "        \"\"\"\n",
    "        if entity_name not in entity_to_id:\n",
    "            raise ValueError(f\"Entidad '{entity_name}' no encontrada en el grafo\")\n",
    "\n",
    "        entity_id = entity_to_id[entity_name]\n",
    "        embedding = model.entity_representations[0](\n",
    "            torch.tensor([entity_id])\n",
    "        ).detach().numpy()[0]\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def calcular_similitudes_paises(result, paises: List[str]):\n",
    "        \"\"\"\n",
    "        Calcula la matriz de similitud entre países usando embeddings\n",
    "        \"\"\"\n",
    "        model = result.model\n",
    "        entity_to_id = result.training.entity_to_id\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"CÁLCULO DE SIMILITUDES CON EMBEDDINGS\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        # Obtener embeddings de todas las países\n",
    "        embeddings = []\n",
    "        paises_validos = []\n",
    "\n",
    "        for pais in paises:\n",
    "            try:\n",
    "                emb = obtener_embedding_entidad(model, pais, entity_to_id)\n",
    "                embeddings.append(emb)\n",
    "                paises_validos.append(pais)\n",
    "            except ValueError as e:\n",
    "                print(f\"⚠ {e}\")\n",
    "\n",
    "        embeddings = np.array(embeddings)\n",
    "\n",
    "        # Calcular matriz de similitud coseno\n",
    "        sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "        # Mostrar resultados\n",
    "        print(f\"\\nMatriz de similitud (coseno) entre {len(paises_validos)} paises:\\n\")\n",
    "        print(f\"{'':20}\", end='')\n",
    "        for p in paises_validos:\n",
    "            print(f\"{p:12}\", end='')\n",
    "        print()\n",
    "\n",
    "        for i, p1 in enumerate(paises_validos):\n",
    "            print(f\"{p1:20}\", end='')\n",
    "            for j, p2 in enumerate(paises_validos):\n",
    "                print(f\"{sim_matrix[i][j]:12.4f}\", end='')\n",
    "            print()\n",
    "\n",
    "        return sim_matrix, paises_validos, embeddings\n",
    "\n",
    "    def encontrar_paises_similares(result, pais_query: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Encuentra los k países más similares a un país dado\n",
    "        \"\"\"\n",
    "        model = result.model\n",
    "        entity_to_id = result.training.entity_to_id\n",
    "        id_to_entity = {v: k for k, v in entity_to_id.items()}\n",
    "\n",
    "        # Obtener todas los países del grafo\n",
    "        todos_paises = [ent for ent in entity_to_id.keys()\n",
    "                        if ent not in ['type', 'Movie', 'director', 'actor', 'genre',\n",
    "                                        'name', 'label', 'SciFi', 'Drama', 'Action',\n",
    "                                        'Thriller', 'Romance', 'Crime']]\n",
    "\n",
    "        # Obtener embedding de el país query\n",
    "        try:\n",
    "            query_emb = obtener_embedding_entidad(model, pais_query, entity_to_id)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return\n",
    "\n",
    "        # Calcular similitud con todas los países\n",
    "        similitudes = []\n",
    "        for pais in todos_paises:\n",
    "            if pais != pais_query:\n",
    "                try:\n",
    "                    emb = obtener_embedding_entidad(model, pais, entity_to_id)\n",
    "                    sim = cosine_similarity([query_emb], [emb])[0][0]\n",
    "                    similitudes.append((pais, sim))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # Ordenar por similitud\n",
    "        similitudes.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"Top {top_k} paises similares a '{pais_query}':\")\n",
    "        print(f\"{'=' * 70}\")\n",
    "        for i, (pais, sim) in enumerate(similitudes[:top_k], 1):\n",
    "            print(f\"{i}. {pais:20} (similitud: {sim:.4f})\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e80c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sbc.load(folder=\"./impl/data/\", format=\"turtle\", filename=\"country_details_ontology_mejorada.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dc51b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCOW ontology contains 170 countries.\n",
      "MCOW ontology contains 20 numerical attributes.\n",
      "14291 triples loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sermo\\AppData\\Local\\Temp\\ipykernel_11256\\2464114926.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(\"trained_embeddings_model.pt\")\n"
     ]
    }
   ],
   "source": [
    "mcow = MCOWAnalyser(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c34d91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afghanistan': ('889', 'AF'),\n",
       " 'albania': ('222', 'AL'),\n",
       " 'algeria': ('262', 'DZ'),\n",
       " 'angola': ('916', 'AO'),\n",
       " 'antigua-and-barbuda': ('781', 'AG'),\n",
       " 'argentina': ('414', 'AR'),\n",
       " 'armenia': ('399', 'AM'),\n",
       " 'austria': ('40', 'AT'),\n",
       " 'azerbaijan': ('227', 'AZ'),\n",
       " 'bahrain': ('398', 'BH'),\n",
       " 'bangladesh': ('902', 'BD'),\n",
       " 'barbados': ('244', 'BB'),\n",
       " 'belarus': ('184', 'BY'),\n",
       " 'belgium': ('31', 'BE'),\n",
       " 'belize': ('242', 'BZ'),\n",
       " 'bhutan': ('917', 'BT'),\n",
       " 'bolivia': ('750', 'BO'),\n",
       " 'bosnia-and-herzegovina': ('225', 'BA'),\n",
       " 'botswana': ('963', 'BW'),\n",
       " 'brazil': ('155', 'BR'),\n",
       " 'brunei': ('921', 'BN'),\n",
       " 'bulgaria': ('219', 'BG'),\n",
       " 'burkina-faso': ('965', 'BF'),\n",
       " 'cambodia': ('424', 'KH'),\n",
       " 'cameroon': ('1009', 'CM'),\n",
       " 'canada': ('16', 'CA'),\n",
       " 'cape-verde': ('1011', 'CV'),\n",
       " 'central-african-republic': ('929', 'CF'),\n",
       " 'chad': ('657', 'TD'),\n",
       " 'chile': ('298', 'CL'),\n",
       " 'colombia': ('739', 'CO'),\n",
       " 'comoros': ('970', 'KM'),\n",
       " 'costa-rica': ('800', 'CR'),\n",
       " 'croatia': ('224', 'HR'),\n",
       " 'cuba': ('241', 'CU'),\n",
       " 'cyprus': ('229', 'CY'),\n",
       " 'czech-republic': ('213', 'CZ'),\n",
       " 'democratic-republic-of-the-congo': ('974', 'CD'),\n",
       " 'djibouti': ('977', 'DJ'),\n",
       " 'dominican-republic': ('786', 'DO'),\n",
       " 'ecuador': ('736', 'EC'),\n",
       " 'egypt': ('79', 'EG'),\n",
       " 'el-salvador': ('792', 'SV'),\n",
       " 'equatorial-guinea': ('983', 'GQ'),\n",
       " 'eritrea': ('986', 'ER'),\n",
       " 'estonia': ('191', 'EE'),\n",
       " 'eswatini': ('1050', 'SZ'),\n",
       " 'ethiopia': ('115', 'ET'),\n",
       " 'federated-states-of-micronesia': ('702', 'FM'),\n",
       " 'fiji': ('712', 'FJ'),\n",
       " 'gabon': ('1000', 'GA'),\n",
       " 'georgia': ('230', 'GE'),\n",
       " 'germany': ('183', 'DE'),\n",
       " 'ghana': ('117', 'GH'),\n",
       " 'greece': ('41', 'GR'),\n",
       " 'grenada': ('769', 'GD'),\n",
       " 'guatemala': ('774', 'GT'),\n",
       " 'guinea': ('1006', 'GN'),\n",
       " 'guinea-bissau': ('1007', 'GW'),\n",
       " 'guyana': ('734', 'GY'),\n",
       " 'haiti': ('790', 'HT'),\n",
       " 'honduras': ('783', 'HN'),\n",
       " 'hong-kong': ('8646', 'HK'),\n",
       " 'hungary': ('28', 'HU'),\n",
       " 'iceland': ('189', 'IS'),\n",
       " 'india': ('668', 'IN'),\n",
       " 'indonesia': ('252', 'ID'),\n",
       " 'iran': ('794', 'IR'),\n",
       " 'iraq': ('796', 'IQ'),\n",
       " 'ireland': ('27', 'IE'),\n",
       " 'italy': ('38', 'IT'),\n",
       " 'jamaica': ('766', 'JM'),\n",
       " 'japan': ('17', 'JP'),\n",
       " 'jordan': ('810', 'JO'),\n",
       " 'kazakhstan': ('232', 'KZ'),\n",
       " 'kenya': ('114', 'KE'),\n",
       " 'kiribati': ('710', 'KI'),\n",
       " 'kuwait': ('817', 'KW'),\n",
       " 'kyrgyzstan': ('813', 'KG'),\n",
       " 'latvia': ('211', 'LV'),\n",
       " 'lebanon': ('822', 'LB'),\n",
       " 'lesotho': ('1013', 'LS'),\n",
       " 'liberia': ('1014', 'LR'),\n",
       " 'libya': ('1016', 'LY'),\n",
       " 'liechtenstein': ('347', 'LI'),\n",
       " 'lithuania': ('37', 'LT'),\n",
       " 'luxembourg': ('32', 'LU'),\n",
       " 'madagascar': ('1019', 'MG'),\n",
       " 'malawi': ('1020', 'MW'),\n",
       " 'malaysia': ('833', 'MY'),\n",
       " 'maldives': ('826', 'MV'),\n",
       " 'mali': ('912', 'ML'),\n",
       " 'malta': ('233', 'MT'),\n",
       " 'mauritania': ('1025', 'MR'),\n",
       " 'mauritius': ('1027', 'MU'),\n",
       " 'mexico': ('96', 'MX'),\n",
       " 'moldova': ('217', 'MD'),\n",
       " 'mongolia': ('711', 'MN'),\n",
       " 'montenegro': ('236', 'ME'),\n",
       " 'mozambique': ('1029', 'MZ'),\n",
       " 'myanmar': ('836', 'MM'),\n",
       " 'namibia': ('1030', 'NA'),\n",
       " 'nepal': ('837', 'NP'),\n",
       " 'netherlands': ('55', 'NL'),\n",
       " 'nicaragua': ('811', 'NI'),\n",
       " 'niger': ('1032', 'NE'),\n",
       " 'nigeria': ('1033', 'NG'),\n",
       " 'north-macedonia': ('221', 'MK'),\n",
       " 'norway': ('20', 'NO'),\n",
       " 'oman': ('842', 'OM'),\n",
       " 'pakistan': ('843', 'PK'),\n",
       " 'panama': ('804', 'PA'),\n",
       " 'papua-new-guinea': ('691', 'PG'),\n",
       " 'paraguay': ('733', 'PY'),\n",
       " \"people's-republic-of-china\": ('148', 'CN'),\n",
       " 'peru': ('419', 'PE'),\n",
       " 'philippines': ('928', 'PH'),\n",
       " 'poland': ('36', 'PL'),\n",
       " 'portugal': ('45', 'PT'),\n",
       " 'qatar': ('846', 'QA'),\n",
       " 'republic-of-the-congo': ('971', 'CG'),\n",
       " 'romania': ('218', 'RO'),\n",
       " 'russia': ('159', 'RU'),\n",
       " 'rwanda': ('1037', 'RW'),\n",
       " 'saint-lucia': ('760', 'LC'),\n",
       " 'saint-vincent-and-the-grenadines': ('757', 'VC'),\n",
       " 'samoa': ('683', 'WS'),\n",
       " 'saudi-arabia': ('851', 'SA'),\n",
       " 'senegal': ('1041', 'SN'),\n",
       " 'serbia': ('403', 'RS'),\n",
       " 'seychelles': ('1042', 'SC'),\n",
       " 'sierra-leone': ('1044', 'SL'),\n",
       " 'singapore': ('334', 'SG'),\n",
       " 'slovakia': ('214', 'SK'),\n",
       " 'slovenia': ('215', 'SI'),\n",
       " 'solomon-islands': ('685', 'SB'),\n",
       " 'south-korea': ('884', 'KR'),\n",
       " 'south-sudan': ('958', 'SS'),\n",
       " 'spain': ('29', 'ES'),\n",
       " 'sri-lanka': ('854', 'LK'),\n",
       " 'sudan': ('1049', 'SD'),\n",
       " 'suriname': ('730', 'SR'),\n",
       " 'sweden': ('34', 'SE'),\n",
       " 'switzerland': ('39', 'CH'),\n",
       " 'são-tomé-and-príncipe': ('1039', 'ST'),\n",
       " 'tajikistan': ('863', 'TJ'),\n",
       " 'tanzania': ('924', 'TZ'),\n",
       " 'thailand': ('869', 'TH'),\n",
       " 'the-bahamas': ('778', 'BS'),\n",
       " 'the-gambia': ('1005', 'GM'),\n",
       " 'timor-leste': ('574', 'TL'),\n",
       " 'togo': ('945', 'TG'),\n",
       " 'tonga': ('678', 'TO'),\n",
       " 'trinidad-and-tobago': ('754', 'TT'),\n",
       " 'tunisia': ('948', 'TN'),\n",
       " 'turkey': ('43', 'TR'),\n",
       " 'tuvalu': ('672', 'TV'),\n",
       " 'uganda': ('1036', 'UG'),\n",
       " 'ukraine': ('212', 'UA'),\n",
       " 'united-arab-emirates': ('878', 'AE'),\n",
       " 'united-kingdom': ('145', 'GB'),\n",
       " 'united-states': ('30', 'US'),\n",
       " 'uruguay': ('77', 'UY'),\n",
       " 'uzbekistan': ('265', 'UZ'),\n",
       " 'vanuatu': ('686', 'VU'),\n",
       " 'venezuela': ('717', 'VE'),\n",
       " 'vietnam': ('881', 'VN'),\n",
       " 'yemen': ('805', 'YE'),\n",
       " 'zambia': ('953', 'ZM'),\n",
       " 'zimbabwe': ('954', 'ZW')}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcow.get_countries_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
